# Learning Predict-and-Simulate Policies From Unorganized Human Motion Data

## Abstract

This code implements the paper "Learning Predict-and-Simulate Policies From Unorganized Human Motion Data". With this system, users can control characters interactively in physics-based environment. 

## Publications

Soohwan Park, Hoseok Ryu, Seyoung Lee, Sunmin Lee, and Jehee Lee., Learning Predict-and-Simulate Policies From Unorganized Human Motion Data, ACM Trans. Graph. 38, 6, (SIGGRAPH Asia 2019)


Project Page : http://mrl.snu.ac.kr/publications/ProjectICC/ICC.html

Youtube : https://youtu.be/9dgUMli0HFU

Paper : http://mrl.snu.ac.kr/publications/ProjectICC/ICC.pdf

## How to install

### OS

We checked that the code works in Ubuntu 16.04 and 18.04. However, we recommand Ubuntu 18.04 because if you install in 16.04, you need to install boost 1.66.

### Install dependencies

```bash
sudo apt-get install -y git python3-dev python3-pip
sudo apt-get install -y python3-tk
pip3 install ipython
pip3 install matplotlib
sudo apt-get install -y curl
sudo apt-get install -y libglew-dev

# dart dependencies
sudo apt-get install -y build-essential cmake pkg-config
sudo apt-get install -y libeigen3-dev libassimp-dev libccd-dev libfcl-dev libboost-regex-dev libboost-system-dev
sudo apt-get install -y libopenscenegraph-dev
sudo apt-get install -y libnlopt-dev
sudo apt-get install -y coinor-libipopt-dev
sudo apt-get install -y libbullet-dev
sudo apt-get install -y libode-dev
sudo apt-get install -y liboctomap-dev
sudo apt-get install -y libflann-dev
sudo apt-get install -y libtinyxml2-dev
sudo apt-get install -y liburdfdom-dev
sudo apt-get install -y libxi-dev libxmu-dev freeglut3-dev
sudo apt-get install -y libopenscenegraph-dev
```

### Install DART

Please refer to http://dartsim.github.io/

```bash
git clone git://github.com/dartsim/dart.git
cd dart
git checkout tags/v6.7.0
mkdir build
cd build
cmake ..
make -j4
sudo make install
```

### Install this repository

```bash
git clone https://github.com/snumrl/ICC.git
cd ICC
mkdir build
cd build
cmake .. -DCMAKE_BUILD_TYPE=Release
make -j4
```

## How to run

### Resource

Our system requires augmented motion data generated by Interactive Character Animation([link]). As a test example, we provied chicken motion data set and its trained networks.


### Compile and Run
- Configurations
Configurations for training and simulation are defined in configurations/\*.xml.(e.g. configurations/chicken.xml) 


- Train motion generator
```bash
cd policy
python3 train_mg.py -m chicken
```

- Train tracking controller
```bash
cd policy
# -s : session name, output networks will be stored in output/{session_name}
# -c : configurations file path
python3 train.py -s chicken -c ../configurations/chicken.xml
```

- Generate trajectory from trained motion generator
After training motion genrator, you can test it in interactive viewer.
```bash
cd policy
# ../build/interactive/interactive path type
# path : network file path
# type : network type, None, smax, rmax
#  None : latest network
#  smax : network whose step is max
#  rmax : network whose reward is max
../build/interactive/interactive ../output/chicken smax
```

